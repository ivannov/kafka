= Data persistence challenges in Microservice applications

:imagesdir: images

Ivan St. Ivanov

UNWE, “Information Technologies and Communications” department

ivan_st_ivanov@yahoo.com

*Paper Abstract*: This paper looks into the data persistence consequences of breaking monolith applications into multiple microservices.
The higher scalability and improved lifecycle of separate deployments come with a cost: if data is persisted in a single storage, separate microservices can't be delivered independently; otherwise transaction boundaries can't be used to ensure data consistency.
The paper looks into the different aspects of the data persistence in a microservices application and proposes optimal solutions for specific microservices usecases beyond those mentioned in general distributed systems research.

*Paper Keywords*: microservices, bounded contexts, data persistence, distributed systems, ACID

== 1. Microservice architecture

Microservice architecture is architectural style that approaches developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API <<Fowler,[1]>>.

Microservices are small and autonomous abstractions that are handling particular business context of the big application.
Each one of them can be implemented using different technology and framework.
Separate microservices can be delivered and scaled independently of each other. <<Newman1,[2]>>

It should be considered as the opposite to the monolith approach, where the application is developed, built and delivered as a single unit.
The latter might consist internally of several components and submodules.
But what is essential is that is deployed as a single archive.

We are going to use a sample moderately large web application to illustrate the how a monolith is turned into microservices and what are the challenges that we face after that.
It is a web store that sells goods.
It was very well developed and its functionality was split into a few submodules.
The diagram bellow presents the most important of them:

image::monolith.png[title="Monolith application", align="center"]

The application consists of a _Store_ submodule, which takes care of all the goods on sale, their current quantity and price.
Then there is the _User management_ submodule, which responsibility is logging in users, keeping track of their profile information and history.
The _Invoices_ submodule is responsible for getting right issuing invoices upon successful sale.
Last but not least, the _Forum_ submodule provides capabilities to e-store users to comment and rate the goods that are on sale.

The monolith model has its own benefits:

* Communication between submodules is straightforward and is based on API calls
* You deploy just a single artifact and let the target platform (i.e. the application server) take care of loading submodules and their dependencies in the proper order
* Monitoring one system is much easier than monitoring multiple ones.
Same with debugging

However, once the monolith application grows, its development and maintenance becomes more problematic compared to a really modular solutions.
We will give two scenarios which prove that claim.

Let's first come back to the delivery model of the e-store.
It is delivered on a single server (real or virtual, doesn't really matter).
This server needs to be running on powerful hardware to meet the application resource requirements.
If in peak moments you decide to scale the application out by adding a new server, you have to purchase or land the same amount of hardware.
Although the higher system requirements come just from the Store submodule, you must duplicate the whole server.

Another usecase is with updating the application.
As its owner, you are delivering new features and bug fixes on a regular basis.
As part of the monolith, you have to run significant set of tests across all the submodules in order to validate a small bug fix in the invoices generation.
Or introduce unnecessary downtime in the Store for example, when you just want to deliver a small feature in the Forum.
To avoid that, you might decide to deliver features and fixes of all modules together once every two weeks.
But in this way the teams that are working on each submodule would lose the autonomy to deliver capabilities at its own pace.

Developing a monolith applications means sticking to one platform for all the submodules.
This means that if the Store performs best if developed in Java backed by Relational Database, you have to use that for the whole e-store.
No matter that another combination would be more appropriate for any of the other modules.

A microservice architecture can easily solve these problems.
According to Dragoni et al <<Dragoni,[3]>>:

* Scaling a microservice architecture does not imply a duplication of all its components and developers can conveniently deploy/dispose instances of services with respect to their load
* Changing a module of a microservice architecture does not require a complete reboot of the whole system.
The reboot regards only the microservices of that module.
* Microservices impose no additional lock-in and developers can freely choose the optimal resources (languages, frameworks, etc.) for the implementation of each microservice besides the communication protocol used for communication between them

So if we split our submodules into microservices, we can get an architecture that is more flexible to scale and easier to maintain:

image::microservices.png[title="Microservice architecture", align="center"]

Now each individual service can be scaled up and out independently from the others.
The teams that deliver each of them can now be responsible for the whole end-to-end delivery of new features as well as for picking the most suitable technology and framework to implement the respective microservice.

Of course, picking a microservice architectural approach does not come without additional implications.
One such implication is that the microservices are not completely isolated semantically.
Which means that their share common concepts.
For example the users defined in User Management service have their representations in all other modules.

The rest of this paper will explain this implication in depth and will describe and compare possible solutions.

== 2. Challenges with microservices data persistence

Modular or not, split to microservices or developed as a monolith, any reasonable application stores and manipulates data.
In a classical three-tier application the single database is considered as a central source of truth.
Even when the business layer is distributed across multiple server nodes, usually the database is shared.

Is this the right approach for microservice architecture as well?

Let's start with a small example.
Suppose that a microservice decides to update its database schema by for example modifying an existing table.
This change has to be really carefully executed so that it doesn't break other services.
In the best possible scenario it would include massive amount of regression testing. <<Newman2,[4]>>

Another drawback of central database is that it is a one size fits all solution.
Thus one of the most powerful features of the microservice architecture - independent technology decision of different services, is gone.
On the other hand, if each service is allowed to pick and use its own data store, the services will determine the most effective way of storing their data. <<Hoehne,[5]>>

Thus we come to the conclusion that that there are strong arguments for isolating each service's data in its own store.
This is known as the _Database per service_ pattern <<Richardson,[6]>>.
It mandates that the data should be kept private to the service and be accessible only via its public API.
Thus it helps ensure that the services are loosely coupled: changes to one service context does not impact any other services.

Each service can use the type of database that is best suited to its needs.
For example, if the Forum service does text searches, it could use ElasticSearch.
If our User Management service also manipulates a social graph, it could use Neo4j.

It doesn't have to be a separate database per service.
You can also have private tables per service or separate schema per service. <<Richardson,[6]>> <<Richardson2,[7]>>

This approach however comes with a completely different class of problems.
Let's take the already mentioned microservices sharing common concepts (like Forum and User Management sharing the concept of a user).
If we use a central storage, we would have a single table with information about the user and foreign key column(s) in the table(s) that refer to it.
But in a single database per service there are no shared tables.
So there we need to have separate copy of the table in each store.

image::separate-table-service.png[title="Database per service pattern", align="center"]

Once we introduce that redundancy, we have to make sure that both tables are kept in sync.
For example if a user changes their name, it will initially go to the User Manager's store.
After that it has to be replicated to all other "copies" of that data, including the Forum.

Using distributed transactions that span multiple services does not help here.
This type of transactions are best avoided because of the CAP theorem.
Moreover, many NoSQL databases (like the Forum in our above example) don’t support them. <<Richardson,[6]>>

The Database per service pattern has also other disadvantages like harder to implement and more difficult to debug.
In the next part we will focus, however, on solving the keeping data in sync challenge.

== 3. Solving the data in sync challenge

We have two microservices that have their own data storage.
Each data storage may use different technology - relational database, document store or even filesystem.
Two distinct services may need to store data about one and the same domain object.
It is very important to note that the different microservices store their own view of the domain object.
So even if they both use let's say relational database for that, the domain object may be stored in a table with completely different structure.
If we go back to our user example - the User Manager stores things like user name, password and profile information.
While the Forum is only interested in user's names and activity.

The problem that we want to solve is what if one of the microservices changes piece of data that is common with the other one.
In our case, what if a user is registered in the User manager?
Or if an existing user changes their profile picture.
These events need to somehow get replicated to the Forum service as well.

One of the options is to make the User Manager call directly some kind of API of the Forum to announce the change.
But this is not a good solution for two reasons:

* It introduces coupling between the two microservices.
It is not necessary for the User Manager to know all the other services that deal with users
* User handling is not Forum's core business.
That is why it should not be part of its public API

The best solution is to use event-driven architecture here.
Services publish events when they update data.
Other service subscribe to events and update their data in response. <<Richardson,[6]>>

image::eda-microservices.png[title="Event driven architecture", align="center"]

Events are immutable structures that capture an interesting point in time that should be broadcast to peers.
Peers will listen to the events in which they’re interested and make decisions based on that data, store that data, store some derivative of that data, update their own data based on some decision made with that data, etc. <<Posta,[8]>>

== 4. Conclusion

== References

[[Fowler]] [1] Martin Fowler and James Lewis. Microservices. 2014. http://martinfowler.com/articles/microservices.html.

[[Newman1]] [2] Sam Newman. Building Microservices, pages 2-7. 2015. O'Reilly

[[Dragoni]] [3] Nicola Dragoni, Saverio Giallorenzo, Alberto Lluch Lafuente, Manuel Mazzara, Fabrizio Montesi, Ruslan Mustafin, Larisa Safina. Microservices: yesterday, today, and tomorrow. 2016. arXiv:1606.04036 [cs.SE]

[[Newman2]] [4] Sam Newman. Building Microservices, page 41. 2015. O'Reilly

[[Hoehne]] [5] Paul Hoehne. Microservices, Persistence: Benefits and Risks. 2016. http://www.marklogic.com/blog/microservices-persistence-benefits-risks/

[[Richardson]] [6] Chris Richardson. Pattern: Database per service. 2016. http://microservices.io/patterns/data/database-per-service.html

[[Richardson2]] [7] Chris Richardson. Does each microservice really need its own database?. 2015. https://plainoldobjects.com/2015/09/02/does-each-microservice-really-need-its-own-database-2/

[[Posta]] [8] Christian Posta. The Hardest Part About Microservices: Your Data. 2016. http://blog.christianposta.com/microservices/the-hardest-part-about-microservices-data/